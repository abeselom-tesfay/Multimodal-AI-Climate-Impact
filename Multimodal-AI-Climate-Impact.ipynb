{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696e290-acad-4abe-ba2c-4dc6065090f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268526cc-ee79-4ab1-a60e-1f91989b4542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import folium  # for geospatial visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4123343e-8fb8-42fb-b4f2-a15d7fb3d617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Visualize Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d7272a-6b3b-45fc-8b99-81294d1b704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example tabular climate data (NOAA or Kaggle subset)\n",
    "climate_data = pd.read_csv(\"climate_data_subset.csv\")\n",
    "print(climate_data.head())\n",
    "\n",
    "# Basic visualization of climate trends\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.lineplot(data=climate_data, x='date', y='temperature')\n",
    "plt.title(\"Sample Temperature Trend\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Temperature (Â°C)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84f00c-4d20-48d8-86f0-be8639f59ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d04806-20ca-4fa4-a9a8-4575cd1068a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values, scaling, encoding categorical features\n",
    "climate_data.fillna(method='ffill', inplace=True)\n",
    "features = climate_data.drop(['target_variable', 'date'], axis=1)\n",
    "target = climate_data['target_variable']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "X_train_tab, X_test_tab, y_train, y_test = train_test_split(\n",
    "    features_scaled, target, test_size=0.2, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3304ddc6-e214-4764-a243-0c850d901e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sample Satellite Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf55ee9-b484-4cd0-8715-f7abd356da56",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = \"satellite_images/\"\n",
    "img_size = (128,128)\n",
    "\n",
    "def load_images(img_dir, img_size):\n",
    "    imgs = []\n",
    "    for fname in os.listdir(img_dir):\n",
    "        if fname.endswith(\".png\") or fname.endswith(\".jpg\"):\n",
    "            img_path = os.path.join(img_dir, fname)\n",
    "            img_array = image.load_img(img_path, target_size=img_size)\n",
    "            img_array = image.img_to_array(img_array)/255.0\n",
    "            imgs.append(img_array)\n",
    "    return np.array(imgs)\n",
    "\n",
    "X_images = load_images(img_dir, img_size)\n",
    "print(\"Satellite images shape:\", X_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8019cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CNN for Image Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a338cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(128,128,3))\n",
    "cnn_base.trainable = False  # freeze base for transfer learning\n",
    "\n",
    "cnn_model = models.Sequential([\n",
    "    cnn_base,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a24c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Tabular + Image Data (Multimodal Fusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2364e456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabular input\n",
    "input_tab = layers.Input(shape=(X_train_tab.shape[1],))\n",
    "x_tab = layers.Dense(128, activation='relu')(input_tab)\n",
    "x_tab = layers.Dropout(0.2)(x_tab)\n",
    "\n",
    "# Image input\n",
    "input_img = layers.Input(shape=(128,128,3))\n",
    "x_img = cnn_model(input_img)\n",
    "\n",
    "# Fusion\n",
    "combined = layers.Concatenate()([x_tab, x_img])\n",
    "x = layers.Dense(256, activation='relu')(combined)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "output = layers.Dense(1, activation='linear')(x)  # regression for climate impact variable\n",
    "\n",
    "multimodal_model = tf.keras.Model(inputs=[input_tab, input_img], outputs=output)\n",
    "\n",
    "multimodal_model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135c320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58d9082",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\n",
    "\n",
    "history = multimodal_model.fit(\n",
    "    [X_train_tab, X_images], y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=16,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
